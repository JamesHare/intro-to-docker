{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"An Intro to Docker This guide contains an introduction to Docker. I will continue to update as I learn more. Overview of Course Working with Containers Swarm Mode and Microservices","title":"Home"},{"location":"#an-intro-to-docker","text":"This guide contains an introduction to Docker. I will continue to update as I learn more.","title":"An Intro to Docker"},{"location":"#overview-of-course","text":"","title":"Overview of Course"},{"location":"#working-with-containers","text":"","title":"Working with Containers"},{"location":"#swarm-mode-and-microservices","text":"","title":"Swarm Mode and Microservices"},{"location":"about/","text":"About Author James Hare Email: harejamesm@gmail.com LinkedIn: https://www.linkedin.com/in/jameshareuk GitHub Portfolio: https://github.com/JamesHare","title":"About"},{"location":"about/#about","text":"","title":"About"},{"location":"about/#author","text":"James Hare Email: harejamesm@gmail.com LinkedIn: https://www.linkedin.com/in/jameshareuk GitHub Portfolio: https://github.com/JamesHare","title":"Author"},{"location":"swarm-mode-and-microservices/configuring-swarm-mode/","text":"Configuring Swarm Mode To build a Swarm with 3 Manager Nodes and 3 Worker Nodes, we will start by executing docker run for 6 containers. These containers can be anything, but should probably just be bare-metal Linux containers for now. We can use the official Ubuntu image from Docker Hub. docker run -d --name [mgr-1] ubuntu Make sure to change the name for each of the containers. When you have 3 contianers running named wrk (worker) and 3 containers named mgr (manager), continue below. Let's initialize the swarm by getting into the mgr-1 container. Once in the first manager container, execute the following command to initialize the swarm: docker swarm init --advertise-addr 192.168.1.5:2377 --listen-addr 192.168.1.5:2377 The --advertise-addr flag lets Docker know that this is the address that we want it to use for swarm related work. The --listen-addr flag lets Docker know that this is the address we want is to listen on for Swarm manager traffic. The ip address has to be valid on your network and should always be the address of the node that you are on. You can use any port that is in your environemnt. However, 2377 is considered the official Swarm port. After execution is complete, a new command will be printed to the console to execute on the Worker Nodes to allow them to join the swarm. Copy this and remember it for later. While we are still on the mgr-1 node, execute the following two commands and observe the output: docker swarm join-token manager docker swarm join-token worker The output of these two commands will give a much longer command that you should execute on all your manager nodes and worker nodes respectively. Docker will be able to tell which is a manager and which is a worker by the last part of the token given on the --token flag. If we want to verify that the swarm has been initialized properly, we can execute the following command: docker info In the output, you will see information about the current swarm. As a side note, if you ever have a worker node that you want to promote to a manager node, you can execute the following command on that worker node: docker node promote [container id]","title":"Configuring Swarm Mode"},{"location":"swarm-mode-and-microservices/configuring-swarm-mode/#configuring-swarm-mode","text":"To build a Swarm with 3 Manager Nodes and 3 Worker Nodes, we will start by executing docker run for 6 containers. These containers can be anything, but should probably just be bare-metal Linux containers for now. We can use the official Ubuntu image from Docker Hub. docker run -d --name [mgr-1] ubuntu Make sure to change the name for each of the containers. When you have 3 contianers running named wrk (worker) and 3 containers named mgr (manager), continue below. Let's initialize the swarm by getting into the mgr-1 container. Once in the first manager container, execute the following command to initialize the swarm: docker swarm init --advertise-addr 192.168.1.5:2377 --listen-addr 192.168.1.5:2377 The --advertise-addr flag lets Docker know that this is the address that we want it to use for swarm related work. The --listen-addr flag lets Docker know that this is the address we want is to listen on for Swarm manager traffic. The ip address has to be valid on your network and should always be the address of the node that you are on. You can use any port that is in your environemnt. However, 2377 is considered the official Swarm port. After execution is complete, a new command will be printed to the console to execute on the Worker Nodes to allow them to join the swarm. Copy this and remember it for later. While we are still on the mgr-1 node, execute the following two commands and observe the output: docker swarm join-token manager docker swarm join-token worker The output of these two commands will give a much longer command that you should execute on all your manager nodes and worker nodes respectively. Docker will be able to tell which is a manager and which is a worker by the last part of the token given on the --token flag. If we want to verify that the swarm has been initialized properly, we can execute the following command: docker info In the output, you will see information about the current swarm. As a side note, if you ever have a worker node that you want to promote to a manager node, you can execute the following command on that worker node: docker node promote [container id]","title":"Configuring Swarm Mode"},{"location":"swarm-mode-and-microservices/rolling-updates/","text":"Rolling Updates Pushing updates to applications is a fact of life. Rolling updates give us a better way of updating our applications. Let's start by removing our service that we had previously deployed. We can do that by executing the following command: docker service rm myservice1 We can verify that the service instances have all been destroyed by running the following command: docker service ls We should see nothing running in the output, except for the headers. Next, we want to create a new overlay network for the service. We can do that by executing the following command: docker network create -d overlay my-net To check that the overlay was created successfully, execute the following command: docker network ls Now let's create our service with the following command: docker service create --name myservice2 --network my-net -p 80:80 --replicas 12 [image name]:[version] Running the following command should show that all of our services were created: docker service ps myservice2 Next, let's take a look at the service with the inspect command: docker service inspect --pretty myservice2 In the output, you will see basic info like the service name, image, ports, etc. and you will also see the update config. This is configuration that we can set when creating the service to instruct Docker on how to handle our rolling updates. For instance, on the service create command above, we could have also specified the --update-parallelism flag and the --update-deplay flag as shown below: docker service create --name myservice2 --network my-net -p 80:80 --replicas 12 [image name]:[version] --update-parallelism 2 --update-delay 10m The update-paralellism flag tells Docker that you want to update a set of 2 service instances at a time and the update-delay flag tells Docker that you want to wait for 10 minutes between updates. We can run the update and set the config on the same service by executing the following command: docker service update --image [image name]:[version] --update-parallelism 2 --update-delay 10s myservice2 To monitor the rolling update, we can execute the service ps command: docker service ps myservice2 After 120 seconds, all 12 of the services will be updated.","title":"Rolling Updates"},{"location":"swarm-mode-and-microservices/rolling-updates/#rolling-updates","text":"Pushing updates to applications is a fact of life. Rolling updates give us a better way of updating our applications. Let's start by removing our service that we had previously deployed. We can do that by executing the following command: docker service rm myservice1 We can verify that the service instances have all been destroyed by running the following command: docker service ls We should see nothing running in the output, except for the headers. Next, we want to create a new overlay network for the service. We can do that by executing the following command: docker network create -d overlay my-net To check that the overlay was created successfully, execute the following command: docker network ls Now let's create our service with the following command: docker service create --name myservice2 --network my-net -p 80:80 --replicas 12 [image name]:[version] Running the following command should show that all of our services were created: docker service ps myservice2 Next, let's take a look at the service with the inspect command: docker service inspect --pretty myservice2 In the output, you will see basic info like the service name, image, ports, etc. and you will also see the update config. This is configuration that we can set when creating the service to instruct Docker on how to handle our rolling updates. For instance, on the service create command above, we could have also specified the --update-parallelism flag and the --update-deplay flag as shown below: docker service create --name myservice2 --network my-net -p 80:80 --replicas 12 [image name]:[version] --update-parallelism 2 --update-delay 10m The update-paralellism flag tells Docker that you want to update a set of 2 service instances at a time and the update-delay flag tells Docker that you want to wait for 10 minutes between updates. We can run the update and set the config on the same service by executing the following command: docker service update --image [image name]:[version] --update-parallelism 2 --update-delay 10s myservice2 To monitor the rolling update, we can execute the service ps command: docker service ps myservice2 After 120 seconds, all 12 of the services will be updated.","title":"Rolling Updates"},{"location":"swarm-mode-and-microservices/scaling-services/","text":"Scaling Services Let's think again about desired state vs current state. Desired state is the state (running, paused, stopped, etc) that we want our container to be in. Current state is, as you may have guessed, the current state that the container is in. If we run the following command, we can see the desired state and current state of our 5 services: docker service ps myservice1 By looking at the output, we should be able to see the node id of our 5 services and determine which of our 6 containers does not have a service attached. If we access one of our service containers, and then execute a command to shut it down, we should see the 6th container register as a service to cover the work load. Access any of the service containers and execute the following command: shutdown -h now Next, run the docker service ps myservice1 command again and you should see 5 services still running. This means that the 6th container picked up the work load automatically because Docker sees that the desired state does not match the current state of the swarm. Which means that Docker Swarm will automatically fix itself, as long as enough containers are running in the swarm to begin with, allowing the DevOps team to be more hands off. To scale the service to 10 services, we can execute the following command: docker service scale myservice1=10 We could give any number as an argument. We can see the current number of services by executing the following command: docker service ps myservice1 In the output, you should see 2 services per node. It should be noted that if we brought back our node that we shutdown, it will not get automatically added back to the swarm. You will have to go in and add it again as a manager node or a worker node.","title":"Scaling Services"},{"location":"swarm-mode-and-microservices/scaling-services/#scaling-services","text":"Let's think again about desired state vs current state. Desired state is the state (running, paused, stopped, etc) that we want our container to be in. Current state is, as you may have guessed, the current state that the container is in. If we run the following command, we can see the desired state and current state of our 5 services: docker service ps myservice1 By looking at the output, we should be able to see the node id of our 5 services and determine which of our 6 containers does not have a service attached. If we access one of our service containers, and then execute a command to shut it down, we should see the 6th container register as a service to cover the work load. Access any of the service containers and execute the following command: shutdown -h now Next, run the docker service ps myservice1 command again and you should see 5 services still running. This means that the 6th container picked up the work load automatically because Docker sees that the desired state does not match the current state of the swarm. Which means that Docker Swarm will automatically fix itself, as long as enough containers are running in the swarm to begin with, allowing the DevOps team to be more hands off. To scale the service to 10 services, we can execute the following command: docker service scale myservice1=10 We could give any number as an argument. We can see the current number of services by executing the following command: docker service ps myservice1 In the output, you should see 2 services per node. It should be noted that if we brought back our node that we shutdown, it will not get automatically added back to the swarm. You will have to go in and add it again as a manager node or a worker node.","title":"Scaling Services"},{"location":"swarm-mode-and-microservices/services/","text":"Services Services are all about simplifying large scale deployments. We can manage services will the following command: docker service <create | ls | ps | inspect | update| rm> We can start a service with the following command: docker service create --name myservice1 -p 8080:8080 --replicas 5 [image name] If we run the \"docker ps\" command after running the command above, we will see 5 service instances (or containers). We can also use the inspect command to get more information about the service: docker service inspect myservice1 The most important value we can observe from the inspect command is the network information and endpoints. If deployed a web app, you will be able to enter any of the endpoints (or ip addresses) of the containers with port 8080 and it shuold serve up your user interface. The beauty of what we just did, is that we automatically get a fully container aware load balancer. Meaning that no matter what container we hit, we will get our service which will be serving our web app. Docker officially calls this load balancer the \"routing mesh.\" As you may remember, we have a total of 6 worker nodes in the swarm. Since we asked docker to spin up (or create) 5 replicas of our service, each one will be attached to a worker node (leaving a 6th worker node with nothing attached).","title":"Services"},{"location":"swarm-mode-and-microservices/services/#services","text":"Services are all about simplifying large scale deployments. We can manage services will the following command: docker service <create | ls | ps | inspect | update| rm> We can start a service with the following command: docker service create --name myservice1 -p 8080:8080 --replicas 5 [image name] If we run the \"docker ps\" command after running the command above, we will see 5 service instances (or containers). We can also use the inspect command to get more information about the service: docker service inspect myservice1 The most important value we can observe from the inspect command is the network information and endpoints. If deployed a web app, you will be able to enter any of the endpoints (or ip addresses) of the containers with port 8080 and it shuold serve up your user interface. The beauty of what we just did, is that we automatically get a fully container aware load balancer. Meaning that no matter what container we hit, we will get our service which will be serving our web app. Docker officially calls this load balancer the \"routing mesh.\" As you may remember, we have a total of 6 worker nodes in the swarm. Since we asked docker to spin up (or create) 5 replicas of our service, each one will be attached to a worker node (leaving a 6th worker node with nothing attached).","title":"Services"},{"location":"swarm-mode-and-microservices/swarm-mode-theory/","text":"Swarm Mode Theory Terms and Concepts When we talk about Clusters we are just talking about Swarms , and in the same way when we talk about Swarms we are just referring to Clusters . For a more specific explination, a Swarm is a collection of Docker Engines joined into a Cluster. Swarm Mode is an entirly optional feature of Docker. Engines that are in a swarm are considered to run in Swarm Mode. A Cluster running in Swarm Mode will consist of one or more Manager Nodes and one or more Worker Nodes . The Manager Nodes maintain the swarm, dispatch tasks and generally look after the state of the Cluster. Manager Nodes are meant to be highly available. The Docker Team recommend 3 - 5 Manager Nodes. Only one Manager Node will be the \"leader\" or the primary node. If a non-leader receives a request, it will proxy the request over to the leader which will execute it against the swarm. Manager Nodes are also considered Worker Nodes. The Worker Nodes just accept tasks from the Manager Node and execute them. A Service is a declarative way of running and scaling tasks. Say you have a backend and frontend web app. You would have two services. One for the backend and one for the frontend. If you want your app to be highly available, you would need to tell Docker to create replicas of your Services. An example command would be as follows: docker service create --name web-fe --replicas 5 ... This creates 5 intsances (containers) of the service that we defined in the command. If one service dies, there is a reconciliation loop running in the background that will see there is only 4 containers running for the service and it will attempt to start up a new one. The reconciliation loop will continue to make sure that your actual state is the same as your desired state of 5 replicas. A Task is the atomic unit of work assigned to a Worker Node. To summarize, in a Swarm , we have a number of Manager Nodes and Worker Nodes . We define Services and declare them to the Manager Node. The Manager then splits the service into tasks and schedules those tasks against available nodes in the Swarm. In order to deploy complex apps consisting of multiple distributed independently scalable services, we have stacks and distributed application bundles.","title":"Swarm Mode Theory"},{"location":"swarm-mode-and-microservices/swarm-mode-theory/#swarm-mode-theory","text":"","title":"Swarm Mode Theory"},{"location":"swarm-mode-and-microservices/swarm-mode-theory/#terms-and-concepts","text":"When we talk about Clusters we are just talking about Swarms , and in the same way when we talk about Swarms we are just referring to Clusters . For a more specific explination, a Swarm is a collection of Docker Engines joined into a Cluster. Swarm Mode is an entirly optional feature of Docker. Engines that are in a swarm are considered to run in Swarm Mode. A Cluster running in Swarm Mode will consist of one or more Manager Nodes and one or more Worker Nodes . The Manager Nodes maintain the swarm, dispatch tasks and generally look after the state of the Cluster. Manager Nodes are meant to be highly available. The Docker Team recommend 3 - 5 Manager Nodes. Only one Manager Node will be the \"leader\" or the primary node. If a non-leader receives a request, it will proxy the request over to the leader which will execute it against the swarm. Manager Nodes are also considered Worker Nodes. The Worker Nodes just accept tasks from the Manager Node and execute them. A Service is a declarative way of running and scaling tasks. Say you have a backend and frontend web app. You would have two services. One for the backend and one for the frontend. If you want your app to be highly available, you would need to tell Docker to create replicas of your Services. An example command would be as follows: docker service create --name web-fe --replicas 5 ... This creates 5 intsances (containers) of the service that we defined in the command. If one service dies, there is a reconciliation loop running in the background that will see there is only 4 containers running for the service and it will attempt to start up a new one. The reconciliation loop will continue to make sure that your actual state is the same as your desired state of 5 replicas. A Task is the atomic unit of work assigned to a Worker Node. To summarize, in a Swarm , we have a number of Manager Nodes and Worker Nodes . We define Services and declare them to the Manager Node. The Manager then splits the service into tasks and schedules those tasks against available nodes in the Swarm. In order to deploy complex apps consisting of multiple distributed independently scalable services, we have stacks and distributed application bundles.","title":"Terms and Concepts"},{"location":"working-with-containers/basic-docker-commands/","text":"The Basic Docker Commands One of the best things about Docker is that it works the exact same way across all platforms. The idea is that you build once and run anywhere. The first command you should run after installing Docker is the version command: docker version In the output you will see the client and server versions running locally on the machine that you're logged onto. The next command you should run is the docker info command: docker info The output will show how many containers and containers you have (how many are running, paused and stopped), how many images you have, the total number CPUs Docker is using, etc. The next command you should run is the Docker Run command: docker run hello-world Let's break this down a bit further. All Docker commands will start with \"docker\" which calls the Docker binary in the background. \"run\" is the standard way of asking Docker to run a new container. \"hello-world\" is the image that you want Docker to run. After hitting return, the client goes and talks to the deamon. The Daemon will check to see if it has a copy of the hello-world image stored locally. If this is the first time you are running this command, it won't be stored locally yet. So the daemon will go and pull the image from Docker Hub, which I will write about later in this guide. The deamon takes the image from Docker Hub and uses it as a template to create a new container. The hello-world image creates a really simple container with a short message from Docker specifying the steps that you just ran and more about what's going on behind the scenes including what you just read above. After the output is printed to the terminal, the container exits. If we run the \"docker ps\" command, we can see that no containers are currently running: docker ps If we run the \"docker ps -a\" it will show us our hello-world container that was running but has now exited (see the STATUS column of the output): docker ps -a Docker ps is a command that you will use a lot to view your containers that are currently running. If you run the \"docker info\" command again you will see that you have 1 container (in the stopped state) and 1 image downloaded: docker info If you want to see the images that you have on your system, run the \"docker images\" command: docker images In the output of this command you will see the repository of image names, the tag (which corresponds to the version of the image), the image ID, when it was created and the size of the image. So to summarize all the information above, here are the commands we looked at. docker run - to run a new container docker ps - to see running and stopped containers docker images - to see info about images stored locally","title":"Basic Docker Commands"},{"location":"working-with-containers/basic-docker-commands/#the-basic-docker-commands","text":"One of the best things about Docker is that it works the exact same way across all platforms. The idea is that you build once and run anywhere. The first command you should run after installing Docker is the version command: docker version In the output you will see the client and server versions running locally on the machine that you're logged onto. The next command you should run is the docker info command: docker info The output will show how many containers and containers you have (how many are running, paused and stopped), how many images you have, the total number CPUs Docker is using, etc. The next command you should run is the Docker Run command: docker run hello-world Let's break this down a bit further. All Docker commands will start with \"docker\" which calls the Docker binary in the background. \"run\" is the standard way of asking Docker to run a new container. \"hello-world\" is the image that you want Docker to run. After hitting return, the client goes and talks to the deamon. The Daemon will check to see if it has a copy of the hello-world image stored locally. If this is the first time you are running this command, it won't be stored locally yet. So the daemon will go and pull the image from Docker Hub, which I will write about later in this guide. The deamon takes the image from Docker Hub and uses it as a template to create a new container. The hello-world image creates a really simple container with a short message from Docker specifying the steps that you just ran and more about what's going on behind the scenes including what you just read above. After the output is printed to the terminal, the container exits. If we run the \"docker ps\" command, we can see that no containers are currently running: docker ps If we run the \"docker ps -a\" it will show us our hello-world container that was running but has now exited (see the STATUS column of the output): docker ps -a Docker ps is a command that you will use a lot to view your containers that are currently running. If you run the \"docker info\" command again you will see that you have 1 container (in the stopped state) and 1 image downloaded: docker info If you want to see the images that you have on your system, run the \"docker images\" command: docker images In the output of this command you will see the repository of image names, the tag (which corresponds to the version of the image), the image ID, when it was created and the size of the image. So to summarize all the information above, here are the commands we looked at. docker run - to run a new container docker ps - to see running and stopped containers docker images - to see info about images stored locally","title":"The Basic Docker Commands"},{"location":"working-with-containers/container-lifecycle/","text":"The Lifecycle of a Container One thing that people generally worry about when using containerization in their tech stack is persistance. Luckily, Docker containers have the capability to persist data after they have been stopped and started again. In fact, it is not until you run the docker remove command (docker rm) that a container's data gets deleted. Let's look at a more complex command: docker run -d --name web -p 80:8080 [namespace]/[image name] We already know what \"docker run\" does. The -d flag tells the deamon to start the container in detached mode. Meaning that it will run in the background and not attach to the current terminal. If we wanted to interact with the container we could instead use the -it flag and then append /bin/bash to the command to enter the container and interact with it. The --name flag just allows us to name our container. The -p flag tells the deamon which ports to map to. The image, which can be anything, is most likely a web service here since we are using port 8080. The 80:8080 argument tells the daemon to map port 80 on the docker host to 8080 on the container. This means that when we go to access the UI at a URL, we can use port 80. Something different about how I specified the image name here, is that I prepended it with a namespace. An example being jamesmhare/image-name. The reason you may sometimes have to do this is that you may be using what is called a second level image. We have already worked with first level images (these are images that live at the root level on Docker Hub and are maintained by official teams). However, second level images are stored in their own namespace and are generally less-offical images that a user maintains. That means that none of the second level images are really all that trustworthy. They may be less secure and you are really at the mercy of the developer. So let's take a quick look at running a container and interacting with it. As mentioned above, we can use the -it flag instead of the -d flag to interact with the containers when using docker run: docker run -it --name web -p 80:8080 [namespace]/[image name] /bin/bash Remember to append /bin/bash to the end of the command. This tells the daemon to start the container with bash running. You will notice that you command prompt has changed and that you are now inside your running container. You can now run all the commands that you may be familiar with (ls, cd, top, etc.) and execute them in the container. One thing to remember is that you cannot just use the exit command to get out of the container as, since /bin/bash is probably the only process running in the container, if you exit out of your docker run command, you will kill the /bin/bash process and the container will automatically stop because it doesn't have any other processes running. Instead, you should use ctrl + p + q. Cleaning Up Containers At this point, I wanted to introduce some other commands that can be useful in cleaning up running containers. This can be helpful when you have a lot of contianers running and you want to interact with them all. To stop all containers, execute the following command: docker stop $(docker ps -aq) To remove all containers, execute the following command: docker rm $(docker ps -aq) To remove all images, execute the following command: docker rmi $(docker ps -aq) Running these three commands will ensure that you have Docker back to the original state as it was when we first started. It's a good way to wipe the slate clean and start over, if you need to.","title":"Container Lifecycle"},{"location":"working-with-containers/container-lifecycle/#the-lifecycle-of-a-container","text":"One thing that people generally worry about when using containerization in their tech stack is persistance. Luckily, Docker containers have the capability to persist data after they have been stopped and started again. In fact, it is not until you run the docker remove command (docker rm) that a container's data gets deleted. Let's look at a more complex command: docker run -d --name web -p 80:8080 [namespace]/[image name] We already know what \"docker run\" does. The -d flag tells the deamon to start the container in detached mode. Meaning that it will run in the background and not attach to the current terminal. If we wanted to interact with the container we could instead use the -it flag and then append /bin/bash to the command to enter the container and interact with it. The --name flag just allows us to name our container. The -p flag tells the deamon which ports to map to. The image, which can be anything, is most likely a web service here since we are using port 8080. The 80:8080 argument tells the daemon to map port 80 on the docker host to 8080 on the container. This means that when we go to access the UI at a URL, we can use port 80. Something different about how I specified the image name here, is that I prepended it with a namespace. An example being jamesmhare/image-name. The reason you may sometimes have to do this is that you may be using what is called a second level image. We have already worked with first level images (these are images that live at the root level on Docker Hub and are maintained by official teams). However, second level images are stored in their own namespace and are generally less-offical images that a user maintains. That means that none of the second level images are really all that trustworthy. They may be less secure and you are really at the mercy of the developer. So let's take a quick look at running a container and interacting with it. As mentioned above, we can use the -it flag instead of the -d flag to interact with the containers when using docker run: docker run -it --name web -p 80:8080 [namespace]/[image name] /bin/bash Remember to append /bin/bash to the end of the command. This tells the daemon to start the container with bash running. You will notice that you command prompt has changed and that you are now inside your running container. You can now run all the commands that you may be familiar with (ls, cd, top, etc.) and execute them in the container. One thing to remember is that you cannot just use the exit command to get out of the container as, since /bin/bash is probably the only process running in the container, if you exit out of your docker run command, you will kill the /bin/bash process and the container will automatically stop because it doesn't have any other processes running. Instead, you should use ctrl + p + q.","title":"The Lifecycle of a Container"},{"location":"working-with-containers/container-lifecycle/#cleaning-up-containers","text":"At this point, I wanted to introduce some other commands that can be useful in cleaning up running containers. This can be helpful when you have a lot of contianers running and you want to interact with them all. To stop all containers, execute the following command: docker stop $(docker ps -aq) To remove all containers, execute the following command: docker rm $(docker ps -aq) To remove all images, execute the following command: docker rmi $(docker ps -aq) Running these three commands will ensure that you have Docker back to the original state as it was when we first started. It's a good way to wipe the slate clean and start over, if you need to.","title":"Cleaning Up Containers"},{"location":"working-with-containers/list-of-commands/","text":"List of Common Docker Commands Some people just wanted a list of common Docker commands, so here we go. Starts a new container: docker run Pulls (copies) images to the Docker Host (running on the local machine): docker pull Lists all images on the Docker Host: docker images Removed images from the Docker Host: docker rmi Lists running containers: docker ps Stops running containers: docker stop Removes (deletes) stopped containers: docker rm","title":"List of Common Docker Commands"},{"location":"working-with-containers/list-of-commands/#list-of-common-docker-commands","text":"Some people just wanted a list of common Docker commands, so here we go. Starts a new container: docker run Pulls (copies) images to the Docker Host (running on the local machine): docker pull Lists all images on the Docker Host: docker images Removed images from the Docker Host: docker rmi Lists running containers: docker ps Stops running containers: docker stop Removes (deletes) stopped containers: docker rm","title":"List of Common Docker Commands"},{"location":"working-with-containers/pulling-and-running-containers/","text":"Pulling and Running Containers As a quick recap of what we have already looked at in this guide, I wanted to provide more infomration on what is going on behind the scenes when we pull and run containers with Docker. So we have our \"Docker Host\" running the docker client and the docker daemon. That combination is also known as the \"Docker Engine.\" We issue the simple docker run command to the client. The client makes the appropriate API calls to the deamon. Based on the fact that the client is calling the docker deamon APIs, we can then understnad that the docker deamon implements the Docker Remote API. After receiving the API call from the client, the docker deamon checks its local store for the image specified in the docker run command. If it does not exist there, the deamon will go and check Docker Hub for the image. Docker Hub is a docker image registery. It's a place where we can store images that we want to use later for contianers. Docker Hub is the default registery that docker will check and it is available on the public Internet. It should be noted that other registeries exist, including secure on-prem registries plus other public and private offerings from third parties. Once the deamon finds the image, it will pull it down to the local machine and then spin up (start) a container using the image.","title":"Pulling and Running Containers"},{"location":"working-with-containers/pulling-and-running-containers/#pulling-and-running-containers","text":"As a quick recap of what we have already looked at in this guide, I wanted to provide more infomration on what is going on behind the scenes when we pull and run containers with Docker. So we have our \"Docker Host\" running the docker client and the docker daemon. That combination is also known as the \"Docker Engine.\" We issue the simple docker run command to the client. The client makes the appropriate API calls to the deamon. Based on the fact that the client is calling the docker deamon APIs, we can then understnad that the docker deamon implements the Docker Remote API. After receiving the API call from the client, the docker deamon checks its local store for the image specified in the docker run command. If it does not exist there, the deamon will go and check Docker Hub for the image. Docker Hub is a docker image registery. It's a place where we can store images that we want to use later for contianers. Docker Hub is the default registery that docker will check and it is available on the public Internet. It should be noted that other registeries exist, including secure on-prem registries plus other public and private offerings from third parties. Once the deamon finds the image, it will pull it down to the local machine and then spin up (start) a container using the image.","title":"Pulling and Running Containers"},{"location":"working-with-containers/what-is-a-container/","text":"What is a Container? Before containerization became popular in the industry, hypervisors were the go to for running apps. A hypervisor grabs physical resources like CPU, RAM, Storage and networks. It slices them into virtual components. Virtual CPU, Virtual RAM, etc. Then it builds virtual machines out of them. Containerization works a bit differently. Instead of slicing the components into virtual components, Docker (and other container engines) slices up Operating System resources. For instance, they slice up the process namespace, the network stack, the storage stack. Every container gets its own Process ID and it's own root file system. In short, \"hypervisor virtualization\" virtualizes physical server resources to build virtual machines. Container Engines like Docker use Operating System virtualization. They create virtual Operating Systems and assign one to each container, inside of which we run applications. They are a lot more lightweight than VM's.","title":"What is a Container?"},{"location":"working-with-containers/what-is-a-container/#what-is-a-container","text":"Before containerization became popular in the industry, hypervisors were the go to for running apps. A hypervisor grabs physical resources like CPU, RAM, Storage and networks. It slices them into virtual components. Virtual CPU, Virtual RAM, etc. Then it builds virtual machines out of them. Containerization works a bit differently. Instead of slicing the components into virtual components, Docker (and other container engines) slices up Operating System resources. For instance, they slice up the process namespace, the network stack, the storage stack. Every container gets its own Process ID and it's own root file system. In short, \"hypervisor virtualization\" virtualizes physical server resources to build virtual machines. Container Engines like Docker use Operating System virtualization. They create virtual Operating Systems and assign one to each container, inside of which we run applications. They are a lot more lightweight than VM's.","title":"What is a Container?"},{"location":"working-with-containers/working-with-images/","text":"Working with Images So now we know how the docker run command works and how containers are based off of images. If you are still confused at this point, think of it this way: Images are stopped Containers Containers are running Images We already know that docker run [image name] will pull down and start a new container using the image name specified. However, we can just pull down an image without running it by using the following command: docker pull [image name] To pull a specific image version we can include the version in the docker pull command as follows: docker pull [image name]:[version] If we don't specify the image version, Docker will just pull the latest release. Remember, you can run the docker images command to list all images that you have downloaded to your local machine: docker images You should take some time to get familiar with Docker Hub. I won't include much info on that here, but head over to https://hub.docker.com and take a look around. Get familiar with the UI. Remember that official images are labeled and are maintained by the teams that built the images and that they often document known security vulnerabilities on older images. Finally, let's look at removing local images. You can remove any image that you have downloaded locally by using the following command: docker rmi [image name] Remember, you can also include the version number if you want to remove that particular image.","title":"Working with Images"},{"location":"working-with-containers/working-with-images/#working-with-images","text":"So now we know how the docker run command works and how containers are based off of images. If you are still confused at this point, think of it this way: Images are stopped Containers Containers are running Images We already know that docker run [image name] will pull down and start a new container using the image name specified. However, we can just pull down an image without running it by using the following command: docker pull [image name] To pull a specific image version we can include the version in the docker pull command as follows: docker pull [image name]:[version] If we don't specify the image version, Docker will just pull the latest release. Remember, you can run the docker images command to list all images that you have downloaded to your local machine: docker images You should take some time to get familiar with Docker Hub. I won't include much info on that here, but head over to https://hub.docker.com and take a look around. Get familiar with the UI. Remember that official images are labeled and are maintained by the teams that built the images and that they often document known security vulnerabilities on older images. Finally, let's look at removing local images. You can remove any image that you have downloaded locally by using the following command: docker rmi [image name] Remember, you can also include the version number if you want to remove that particular image.","title":"Working with Images"}]}